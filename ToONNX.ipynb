{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "import torch\n",
    "from Model import convnext\n",
    "\n",
    "\n",
    "#Function to Convert to ONNX\n",
    "def Convert_ONNX():\n",
    "    path = \"Trained_Model/CONVNEXT62_0.696.pth\"\n",
    "    model = torch.load(path)\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    # set the model to inference mode\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    # Let's create a dummy input tensor\n",
    "    dummy_input = torch.randn(1, 3, 224, 224, requires_grad=True).to(device)\n",
    "\n",
    "    # Export the model\n",
    "    torch.onnx.export(\n",
    "        model,  # model being run \n",
    "        dummy_input,  # model input (or a tuple for multiple inputs) \n",
    "        \"ImageClassifier.onnx\",  # where to save the model  \n",
    "        export_params=\n",
    "        True,  # store the trained parameter weights inside the model file \n",
    "        opset_version=10,  # the ONNX version to export the model to \n",
    "        do_constant_folding=\n",
    "        True,  # whether to execute constant folding for optimization \n",
    "        input_names=['modelInput'],  # the model's input names \n",
    "        output_names=['modelOutput'],  # the model's output names \n",
    "        dynamic_axes={\n",
    "            'modelInput': {\n",
    "                0: 'batch_size'\n",
    "            },  # variable length axes \n",
    "            'modelOutput': {\n",
    "                0: 'batch_size'\n",
    "            }\n",
    "        })\n",
    "    print(\" \")\n",
    "    print('Model has been converted to ONNX')\n",
    "\n",
    "\n",
    "# Let's build our model\n",
    "#train(5)\n",
    "#print('Finished Training')\n",
    "\n",
    "# Test which classes performed well\n",
    "#testAccuracy()\n",
    "\n",
    "# Let's load the model we just created and test the accuracy per label\n",
    "# model = convnext.convnext_base(pretrained=False)\n",
    "# model.load_state_dict(torch.load(path))\n",
    "\n",
    "# Test with batch of images\n",
    "#testBatch()\n",
    "# Test how the classes performed\n",
    "#testClassess()\n",
    "\n",
    "# Conversion to ONNX\n",
    "Convert_ONNX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "model = 'ImageClassifier.onnx'\n",
    "\n",
    "onnx.save(onnx.shape_inference.infer_shapes(onnx.load(model)), model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a798a8c48037f1867761d0f6ae6ee6f6529b8b462e421325d143d37b87845564"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
