{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transfroms\n",
    "from torch.autograd import Variable\n",
    "from torchtoolbox.tools import mixup_data,mixup_criterion\n",
    "from torchtoolbox.transform import Cutout\n",
    "from Model.convnext import convnext_base,convnext_tiny\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modellr = torch.optim.lr_scheduler.OneCycleLR\n",
    "modellr = 1e-4\n",
    "BATCH_SIZE = 128\n",
    "WORKERS = 16\n",
    "EPOCHS = 50\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfrom = transfroms.Compose([\n",
    "    transfroms.Resize((224, 224)),\n",
    "    transfroms.RandAugment(),\n",
    "    #transfroms.AutoAugment(),\n",
    "    transfroms.RandomAutocontrast(),\n",
    "    transfroms.RandomRotation(180),\n",
    "    transfroms.RandomHorizontalFlip(),\n",
    "    #transfroms.ColorJitter(0.3,0.3,0.3),\n",
    "    # transfroms.RandomCrop(),\n",
    "    Cutout(0.3),\n",
    "    transfroms.ToTensor(),\n",
    "    transfroms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "transfroms_test = transfroms.Compose([\n",
    "    transfroms.Resize((224, 224)),\n",
    "    transfroms.RandAugment(),\n",
    "    #transfroms.AutoAugment(),\n",
    "    transfroms.RandomAutocontrast(),\n",
    "    transfroms.RandomRotation(180),\n",
    "    transfroms.RandomHorizontalFlip(),\n",
    "    #transfroms.ColorJitter(0.3,0.3,0.3),\n",
    "    # transfroms.RandomCrop(),\n",
    "    Cutout(0.3),\n",
    "    transfroms.ToTensor(),\n",
    "    transfroms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = {\"0\":0,\"1\":1,\"2\":2,\"3\":3,\"4\":4,\"5\":5,\"6\":6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anger disgust fear happy sad surprised normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeedlingData(data.Dataset):\n",
    "\n",
    "    def __init__(self, root, transforms=None, train=True, test=False):\n",
    "        self.test = test\n",
    "        self.transforms = transforms\n",
    "        if self.test:\n",
    "            imgs = [os.path.join(root, img) for img in os.listdir(root)]\n",
    "            self.imgs = imgs\n",
    "        else:\n",
    "            img_labels = [os.path.join(root, img) for img in os.listdir(root)]\n",
    "            imgs = []\n",
    "            for imglabel in img_labels:\n",
    "                for imgname in os.listdir(imglabel):\n",
    "                    imgpath = os.path.join(imglabel, imgname)\n",
    "                    imgs.append(imgpath)\n",
    "            trainval_file, val_file = train_test_split(imgs,\n",
    "                                                       test_size=0.3,\n",
    "                                                       random_state=42)\n",
    "            if train:\n",
    "                self.imgs = trainval_file\n",
    "            else:\n",
    "                self.imgs = val_file\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.imgs[index]\n",
    "        img_path = img_path.replace(\"\\\\\", \"/\")\n",
    "        if self.test:\n",
    "            label = -1\n",
    "        else:\n",
    "            labelname = img_path.split('/')[-2]\n",
    "            label = Labels[labelname]\n",
    "        data = Image.open(img_path).convert('RGB')\n",
    "        data = self.transforms(data)\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = SeedlingData('./datasets/train',transforms=transfrom,train=True)\n",
    "dataset_test = SeedlingData('./datasets/train',transforms=transfrom,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           #num_workers=WORKERS,\n",
    "                                           pin_memory=True,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          #num_workers=WORKERS,\n",
    "                                          pin_memory=True,\n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = SoftTargetCrossEntropy()\n",
    "model_ft = convnext_base(pretrained=True)\n",
    "num_ftrs = model_ft.head.in_features\n",
    "#num_ftrs = model_ft.in_features\n",
    "model_ft.head = nn.Linear(num_ftrs, 7) # 7种表情\n",
    "model_ft.to(DEVICE)\n",
    "print(model_ft)\n",
    "# 选择简单暴力的Adam优化器，学习率调低\n",
    "#optimizer = optim.Adam(model_ft.parameters(), lr=modellr)\n",
    "#optimizer = optim.SGD(model_ft.parameters(),lr=modellr)\n",
    "optimizer = optim.RAdam(model_ft.parameters(),lr=modellr)\n",
    "cosine_schedule = optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer,T_max=20,eta_min=1e-9)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(dataset_train), epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_COUNT = 0\n",
    "ACC_LIST=[]\n",
    "LOSS_LIST=[]\n",
    "ACC=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.2\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    sum_loss = 0\n",
    "    lr_now = modellr\n",
    "    total_num = len(train_loader.dataset)\n",
    "    print(total_num, len(train_loader))\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "        data, labels_a, labels_b, lam = mixup_data(data, target, alpha)\n",
    "        optimizer.zero_grad()\n",
    "        # output = model(data)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            loss = mixup_criterion(criterion, model(data), labels_a, labels_b, lam)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scheduler.step()\n",
    "        lr_now = scheduler.get_last_lr()\n",
    "        scaler.update()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        print_loss = loss.data.item()\n",
    "        sum_loss += print_loss\n",
    "        # if (batch_idx + 1) % 10 == 0:\n",
    "        #     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tlr={}'.format(\n",
    "        #         epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "        #                100. * (batch_idx + 1) / len(train_loader), loss.item(),lr_now))\n",
    "    ave_loss = sum_loss / len(train_loader)\n",
    "    LOSS_LIST.append(ave_loss)\n",
    "    print('Epoch:{},loss:{},lr:{}'.format(epoch, ave_loss,lr_now))\n",
    "\n",
    "# 验证过程\n",
    "def val(model, device, test_loader):\n",
    "    global ACC\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total_num = len(test_loader.dataset)\n",
    "    print(total_num, len(test_loader))\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = Variable(data).to(device), Variable(target).to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            correct += torch.sum(pred == target)\n",
    "            print_loss = loss.data.item()\n",
    "            test_loss += print_loss\n",
    "        correct = correct.data.item()\n",
    "        acc = correct / total_num\n",
    "        avgloss = test_loss / len(test_loader)\n",
    "        print('\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            avgloss, correct, len(test_loader.dataset), 100 * acc))\n",
    "        ACC_LIST.append(acc)\n",
    "        if acc > ACC:\n",
    "            torch.save(model_ft, 'model_' + str(epoch) + '_' + str(round(acc, 3)) + '.pth')\n",
    "            ACC = acc\n",
    "\n",
    "\n",
    "# 训练\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model_ft, DEVICE, train_loader, optimizer, epoch)\n",
    "    cosine_schedule.step()\n",
    "    val(model_ft, DEVICE, test_loader)\n",
    "    if EPOCHS%10==0:\n",
    "        #seaborn.set(style='whitegrid') #darkgrid, whitegrid, dark, white, ticks\n",
    "        sns.set(palette='twilight')\n",
    "        sns.relplot(kind='line',data=ACC_LIST)\n",
    "        plt.xlabel(\"Epoche Time\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.ylim(0,1)\n",
    "        #plt.ylim(top=1,bottom=0)\n",
    "        sns.relplot(kind='line',data=LOSS_LIST)\n",
    "        plt.ylabel(\"Loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1882425c3b4fabc3d9812b2bb88e573da3722c6cd108cda16b062a3868ec4930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
