{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transfroms\n",
    "from torch.autograd import Variable\n",
    "from torchtoolbox.tools import mixup_data,mixup_criterion\n",
    "from torchtoolbox.transform import Cutout\n",
    "from Model.convnext import convnext_tiny\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modellr = 1e-4\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 300\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfrom = transfroms.Compose([\n",
    "    transfroms.Resize((224, 224)),\n",
    "    Cutout(),\n",
    "    transfroms.ToTensor(),\n",
    "    transfroms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "transfroms_test = transfroms.Compose([\n",
    "    transfroms.Resize((224, 224)),\n",
    "    Cutout(),\n",
    "    transfroms.ToTensor(),\n",
    "    transfroms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = {\"0\":0,\"1\":1,\"2\":2,\"3\":3,\"4\":4,\"5\":5,\"6\":6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anger disgust fear happy sad surprised normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeedlingData(data.Dataset):\n",
    "\n",
    "    def __init__(self, root, transforms=None, train=True, test=False):\n",
    "        self.test = test\n",
    "        self.transforms = transforms\n",
    "        if self.test:\n",
    "            imgs = [os.path.join(root, img) for img in os.listdir(root)]\n",
    "            self.imgs = imgs\n",
    "        else:\n",
    "            img_labels = [os.path.join(root, img) for img in os.listdir(root)]\n",
    "            imgs = []\n",
    "            for imglabel in img_labels:\n",
    "                for imgname in os.listdir(imglabel):\n",
    "                    imgpath = os.path.join(imglabel, imgname)\n",
    "                    imgs.append(imgpath)\n",
    "            trainval_file, val_file = train_test_split(imgs,\n",
    "                                                       test_size=0.3,\n",
    "                                                       random_state=42)\n",
    "            if train:\n",
    "                self.imgs = trainval_file\n",
    "            else:\n",
    "                self.imgs = val_file\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.imgs[index]\n",
    "        img_path = img_path.replace(\"\\\\\", \"/\")\n",
    "        if self.test:\n",
    "            label = -1\n",
    "        else:\n",
    "            labelname = img_path.split('/')[-2]\n",
    "            label = Labels[labelname]\n",
    "        data = Image.open(img_path).convert('RGB')\n",
    "        data = self.transforms(data)\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = SeedlingData('./datasets/train',transforms=transfrom,train=True)\n",
    "dataset_test = SeedlingData('./datasets/train',transforms=transfrom,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = SoftTargetCrossEntropy()\n",
    "model_ft = convnext_tiny(pretrained=True)\n",
    "num_ftrs = model_ft.head.in_features\n",
    "#num_ftrs = model_ft.in_features\n",
    "model_ft.head = nn.Linear(num_ftrs, 7) # 7种表情\n",
    "model_ft.to(DEVICE)\n",
    "print(model_ft)\n",
    "# 选择简单暴力的Adam优化器，学习率调低\n",
    "#optimizer = optim.Adam(model_ft.parameters(), lr=modellr)\n",
    "optimizer = optim.SGD(model_ft.parameters(),lr=modellr)\n",
    "cosine_schedule = optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer,T_max=20,eta_min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.2\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    sum_loss = 0\n",
    "    total_num = len(train_loader.dataset)\n",
    "    print(total_num, len(train_loader))\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "        data, labels_a, labels_b, lam = mixup_data(data, target, alpha)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = mixup_criterion(criterion, output, labels_a, labels_b, lam)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print_loss = loss.data.item()\n",
    "        sum_loss += print_loss\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                       100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
    "    ave_loss = sum_loss / len(train_loader)\n",
    "    print('epoch:{},loss:{}'.format(epoch, ave_loss))\n",
    "\n",
    "ACC=0\n",
    "# 验证过程\n",
    "def val(model, device, test_loader):\n",
    "    global ACC\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total_num = len(test_loader.dataset)\n",
    "    print(total_num, len(test_loader))\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = Variable(data).to(device), Variable(target).to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            correct += torch.sum(pred == target)\n",
    "            print_loss = loss.data.item()\n",
    "            test_loss += print_loss\n",
    "        correct = correct.data.item()\n",
    "        acc = correct / total_num\n",
    "        avgloss = test_loss / len(test_loader)\n",
    "        print('\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            avgloss, correct, len(test_loader.dataset), 100 * acc))\n",
    "        if acc > ACC:\n",
    "            torch.save(model_ft, 'model_' + str(epoch) + '_' + str(round(acc, 3)) + '.pth')\n",
    "            ACC = acc\n",
    "\n",
    "\n",
    "# 训练\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model_ft, DEVICE, train_loader, optimizer, epoch)\n",
    "    cosine_schedule.step()\n",
    "    val(model_ft, DEVICE, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "classes = ('Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed',\n",
    "           'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n",
    "           'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet')\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(\"model_8_0.971.pth\")\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "path = 'data/test/'\n",
    "testList = os.listdir(path)\n",
    "for file in testList:\n",
    "    img = Image.open(path + file)\n",
    "    img = transform_test(img)\n",
    "    img.unsqueeze_(0)\n",
    "    img = Variable(img).to(DEVICE)\n",
    "    out = model(img)\n",
    "    # Predict\n",
    "    _, pred = torch.max(out.data, 1)\n",
    "    print('Image Name:{},predict:{}'.format(file, classes[pred.data.item()]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1882425c3b4fabc3d9812b2bb88e573da3722c6cd108cda16b062a3868ec4930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
